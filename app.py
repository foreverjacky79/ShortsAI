import streamlit as st
import requests
import json
import os
import webbrowser
import time
import pandas as pd
import yt_dlp
from datetime import datetime, timedelta, timezone
from googleapiclient.discovery import build
import google.generativeai as genai
import pyperclip
import re
import threading

# ===== æ ¸å¿ƒå‡½æ•¸ï¼ˆå¿…é ˆæ”¾åœ¨æœ€å‰é¢ï¼‰=====
@st.cache_data(ttl=300)
def fetch_trending_shorts(api_key, keyword, days, min_views, min_subs, max_results, min_viral_score, max_duration):
    """YouTube Shorts è¶¨å‹¢æœå°‹"""
    youtube = build("youtube", "v3", developerKey=api_key)
    published_after = (datetime.now(timezone.utc) - timedelta(days=days)).strftime("%Y-%m-%dT%H:%M:%SZ")

    search_response = youtube.search().list(
        q=keyword, part="id", type="video", order="viewCount",
        maxResults=max_results, publishedAfter=published_after
    ).execute()

    video_ids = [item["id"]["videoId"] for item in search_response["items"]]
    if not video_ids: return []

    video_response = youtube.videos().list(
        part="snippet,statistics,contentDetails", id=",".join(video_ids)
    ).execute()

    results = []
    for item in video_response["items"]:
        duration_raw = item["contentDetails"]["duration"]
        total_seconds = parse_duration_to_seconds(duration_raw)
        if total_seconds > max_duration: continue

        stats = item["statistics"]
        snippet = item["snippet"]
        views = int(stats.get("viewCount", 0))
        if views < min_views: continue

        published = datetime.fromisoformat(snippet["publishedAt"].replace("Z", "+00:00"))
        now = datetime.now(timezone.utc)
        hours_passed = max((now - published).total_seconds() / 3600, 1)
        viral_score = views / hours_passed
        
        if viral_score < min_viral_score: continue

        m, s = divmod(total_seconds, 60)
        duration_display = f"{m}:{s:02d}"

        results.append({
            "title": snippet["title"],
            "views": views,
            "duration": duration_display,
            "hours": round(hours_passed, 1),
            "viral_score": round(viral_score, 2),
            "published": published.strftime("%Y-%m-%d %H:%M"),
            "url": f"https://www.youtube.com/watch?v={item['id']}"
        })

    results.sort(key=lambda x: x["viral_score"], reverse=True)
    return results

def parse_duration_to_seconds(duration_str):
    hours = re.search(r'(\d+)H', duration_str)
    minutes = re.search(r'(\d+)M', duration_str)
    seconds = re.search(r'(\d+)S', duration_str)
    h = int(hours.group(1)) if hours else 0
    m = int(minutes.group(1)) if minutes else 0
    s = int(seconds.group(1)) if seconds else 0
    return h * 3600 + m * 60 + s

def ai_generate_prompt(gemini_api_key, video_url, progress_callback=None):
    if not gemini_api_key:
        return "âš ï¸ è«‹å…ˆè¼¸å…¥ Gemini API Keyï¼"
    
    try:
        if progress_callback: progress_callback("ðŸ“¥ ä¸‹è¼‰å½±ç‰‡...")
        ydl_opts = {'format': 'best[ext=mp4]/tiny', 'outtmpl': 'temp_ai_input.%(ext)s', 'overwrites': True}
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([video_url])

        if progress_callback: progress_callback("ðŸ”— é€£ç·š Gemini...")
        client = genai.GenerativeModel('gemini-1.5-flash', api_key=gemini_api_key)
        
        video_file_path = "temp_ai_input.mp4"
        if not os.path.exists(video_file_path):
            video_file_path = "temp_ai_input.webm"

        if progress_callback: progress_callback("ðŸ§  AI åˆ†æžä¸­...")
        prompt = """Analyze this video and create a detailed English prompt for AI video generation (Sora/Runway). Include: character features, actions, environment, camera movement, lighting."""
        
        response = client.generate_content([prompt, video_file_path])
        
        # æ¸…ç†
        for ext in ["mp4", "webm"]:
            temp_path = f"temp_ai_input.{ext}"
            if os.path.exists(temp_path): os.remove(temp_path)
        
        return response.text
    except Exception as e:
        return f"âŒ AI åˆ†æžå¤±æ•—: {str(e)}"

@st.cache_data(ttl=300)
def get_current_version():
    try:
        response = requests.get("https://raw.githubusercontent.com/foreverjacky79/ShortsAI/refs/heads/main/version.txt", timeout=5)
        return response.text.strip()
    except:
        return "1.0.5"

# ===== Streamlit UIï¼ˆå‡½æ•¸å®šç¾©å¾Œï¼‰=====
st.set_page_config(page_title="YouTube Shorts è¶¨å‹¢åˆ†æž", page_icon="ðŸŽ¥", layout="wide")

st.title(f"ðŸŽ¥ YouTube Shorts è¶¨å‹¢åˆ†æžå·¥å…· v{get_current_version()}")

# Sidebar
st.sidebar.header("âš™ï¸ è¨­å®š")
api_key = st.sidebar.text_input("YouTube API Key", type="password")
gemini_key = st.sidebar.text_input("Gemini API Key", type="password")

st.sidebar.header("ðŸ” æœå°‹æ¢ä»¶")
col1, col2 = st.sidebar.columns(2)
keyword = col1.text_input("é—œéµå­—", "animal")
days = col2.number_input("å¤©æ•¸", 1, 30, 7)

col3, col4 = st.sidebar.columns(2)
min_views = col3.number_input("æœ€ä½Žè§€çœ‹", 10000, 1000000, 100000)
max_duration = col4.number_input("æœ€é•·ç§’æ•¸", 10, 60, 20)

col5, col6 = st.sidebar.columns(2)
min_viral = col5.number_input("çˆ†ç™¼æŒ‡æ•¸", 1000.0, 10000.0, 3000.0)
max_results = col6.number_input("æœ€å¤§çµæžœ", 10, 100, 30)

# æœå°‹æŒ‰éˆ•
if st.sidebar.button("ðŸš€ é–‹å§‹æœå°‹", type="primary"):
    if api_key:
        with st.spinner("æœå°‹ä¸­..."):
            results = fetch_trending_shorts(api_key, keyword, days, min_views, 0, max_results, min_viral, max_duration)
            st.session_state.results = results
            st.success(f"æ‰¾åˆ° {len(results)} å€‹ç†±é–€ Shortsï¼")
    else:
        st.error("è«‹è¼¸å…¥ YouTube API Key")

# ä¸»ä»‹é¢
if "results" in st.session_state and st.session_state.results:
    df = pd.DataFrame(st.session_state.results)
    df = df.sort_values("viral_score", ascending=False)
    
    st.subheader(f"ðŸ“Š æœå°‹çµæžœ ({len(df)} ç­†)")
    
    # é¸æ“‡å½±ç‰‡
    selected_idx = st.selectbox("é¸æ“‡å½±ç‰‡ï¼š", range(len(df)), 
                               format_func=lambda i: f"{df.iloc[i]['title'][:50]}... ({df.iloc[i]['views']:,}è§€çœ‹)")
    
    selected = df.iloc[selected_idx]
    
    # å½±ç‰‡è³‡è¨Š
    col1, col2, col3 = st.columns(3)
    col1.metric("è§€çœ‹æ•¸", f"{selected['views']:,}", f"{selected['viral_score']:.0f}")
    col2.metric("æ™‚é•·", selected['duration'])
    col3.metric("ç™¼å¸ƒ", f"{selected['hours']}å°æ™‚å‰")
    
    st.info(selected['title'])
    
    # å‹•ä½œæŒ‰éˆ•
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ðŸŒ é–‹å•Ÿå½±ç‰‡"): webbrowser.open(selected['url'])
    with col2:
        if st.button("ðŸ“‹ è¤‡è£½é€£çµ"): 
            pyperclip.copy(selected['url'])
            st.success("å·²è¤‡è£½ï¼")
    with col3:
        if st.button("ðŸ¤– AI åˆ†æž", disabled=not gemini_key):
            if gemini_key:
                with st.spinner("AI åˆ†æžä¸­..."):
                    result = ai_generate_prompt(gemini_key, selected['url'])
                    st.session_state.ai_result = result
    
    # å®Œæ•´è¡¨æ ¼
    st.dataframe(df[['title', 'views', 'duration', 'viral_score', 'published']], 
                use_container_width=True)
    
    # AI çµæžœ
    if "ai_result" in st.session_state:
        st.subheader("ðŸŽ¨ AI ç”Ÿæˆçš„ Prompt")
        st.code(st.session_state.ai_result)
        st.download_button("ä¸‹è¼‰", st.session_state.ai_result, "prompt.txt")

# æ‰‹å‹•åˆ†æž
st.subheader("ðŸ”— æ‰‹å‹•è¼¸å…¥ URL")
manual_url = st.text_input("YouTube é€£çµ")
if st.button("AI åˆ†æž", disabled=not gemini_key or not manual_url):
    if gemini_key:
        with st.spinner("åˆ†æžä¸­..."):
            result = ai_generate_prompt(gemini_key, manual_url)
            st.session_state.ai_result = result
